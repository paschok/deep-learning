{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - DL Tutorial 09\n",
    "\n",
    "### Student names: Anastasia Karsten, Pavlo Mospan\n",
    "\n",
    "Submit you solution by 14 June to manuel.milling@informatik.uni-augsburg.de AND maurice.gerczuk@informatik.uni-augsburg.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "w2v_embedding_file = \"data/embeddings/word2vec-40k-wiki-news-300d.vec\"\n",
    "ewe_embedding_file = \"data/embeddings/ewe-40k-300d.vec\"\n",
    "\n",
    "train_tsv = \"data/isear/train.tsv\"\n",
    "val_tsv = \"data/isear/val.tsv\"\n",
    "test_tsv = \"data/isear/test.tsv\"\n",
    "\n",
    "oov_id=1\n",
    "pad_id=0\n",
    "seq_length=128\n",
    "\n",
    "lr=0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load word2vec embedding matrix and create word-index-dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "w2v_emb_matrix:\t\t(40001, 300)\nw2v_word2idx shape:\t40000\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "def read_embedding_matrix(embedding_file):\n",
    "\n",
    "    # Read data as a float to save the embedings\n",
    "    data = np.genfromtxt(embedding_file, delimiter=\" \")\n",
    "    data=np.delete(data,0,1)\n",
    "\n",
    "    zeros = np.zeros(data.shape[1])\n",
    "    means = np.mean(data, axis = 0)\n",
    "\n",
    "    matrix = np.insert(data, 0, zeros, axis=0)\n",
    "    matrix = np.insert(matrix, 1, means, axis=0) \n",
    "\n",
    "    # Read data as string to save in dict\n",
    "    data = np.genfromtxt(embedding_file, dtype=str, delimiter=\" \")\n",
    "    dictionary = {}\n",
    "    dictionary[\"0\"] = 0\n",
    "    dictionary[\"NaN\"] = 1\n",
    "    for i in range(data.shape[0]):\n",
    "        dictionary[str(data[i][0])] = (i + 2)  \n",
    "\n",
    "    return matrix, dictionary\n",
    "    \n",
    "\n",
    "w2v_emb_matrix, w2v_word2idx = read_embedding_matrix(w2v_embedding_file)\n",
    "print(f\"w2v_emb_matrix:\\t\\t{w2v_emb_matrix.shape}\")\n",
    "print(f\"w2v_word2idx shape:\\t{len(w2v_word2idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepare data:\n",
    "- Load the sentences from the tsv files.\n",
    "- Unify sentences (lower case, remove punctuation, etc.).\n",
    "- Split sentences into words.\n",
    "- Cut and zero pad sentences.\n",
    "- Map words to indices.\n",
    "- Map string labels to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train shape:\t\t(5976, 128)\nx_validation shape:\t(752, 128)\nx_test shape:\t\t(736, 128)\ny_train shape:\t\t(5976, 7)\ny_validation shape:\t(752, 7)\ny_test shape:\t\t(736, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def read_tsv(tsv, word2idx, oov_id=1, pad_id=0, seq_length=128):\n",
    "    data = np.genfromtxt(tsv, dtype=str, case_sensitive=\"lower\", delimiter=(\"\\t\"), deletechars=\".\")\n",
    "\n",
    "    # Get the last word, assign it an int and one-hot encode everything\n",
    "    y = [i[1] for i in data]\n",
    "    y = np.asarray(y)\n",
    "    y = pandas.factorize(y)[0]\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    # Get the sentences\n",
    "    x = [i[0] for i in data]\n",
    "    \n",
    "    # Split sentences into words and get rid of punctuation\n",
    "    hold = []\n",
    "    hold.append([[re.split(' |-|\\\\.|\\\\!|\\\\?|\\\\(|\\\\) ', item) for item in x]])\n",
    "\n",
    "    # Unpack the senteces\n",
    "    hold = hold[0]\n",
    "    hold = hold[0]\n",
    "\n",
    "    for sentence in hold:\n",
    "        # Get rid of empty words from the bracket removal\n",
    "        for word in sentence:\n",
    "            if word == '' or word == ' ':\n",
    "                sentence.remove(word) \n",
    "\n",
    "        # Lowercase everything\n",
    "        for k in range(len(sentence)):\n",
    "            sentence[k] = sentence[k].lower()\n",
    "\n",
    "            # Look up the word in dict\n",
    "            if sentence[k] in word2idx:\n",
    "                sentence[k] = word2idx[sentence[k]]\n",
    "            else:\n",
    "                sentence[k] = oov_id\n",
    "        # Make als sentences seq_lenght long\n",
    "        if len(sentence) < seq_length:\n",
    "            for f in range(seq_length - len(sentence)):\n",
    "                sentence.append(pad_id)\n",
    "        elif len(sentence) > seq_length:\n",
    "            for f in range(seq_length, len(sentence)):\n",
    "                sentence.pop()\n",
    "\n",
    "    x = np.array(hold)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_X, train_y = read_tsv(train_tsv, w2v_word2idx, oov_id=oov_id, pad_id=pad_id, seq_length=seq_length)\n",
    "val_X, val_y = read_tsv(val_tsv, w2v_word2idx, oov_id=oov_id, pad_id=pad_id, seq_length=seq_length)\n",
    "test_X, test_y = read_tsv(test_tsv, w2v_word2idx, oov_id=oov_id, pad_id=pad_id, seq_length=seq_length)\n",
    "\n",
    "print(f\"x_train shape:\\t\\t{train_X.shape}\")\n",
    "print(f\"x_validation shape:\\t{val_X.shape}\")\n",
    "print(f\"x_test shape:\\t\\t{test_X.shape}\")\n",
    "print(f\"y_train shape:\\t\\t{train_y.shape}\")\n",
    "print(f\"y_validation shape:\\t{val_y.shape}\")\n",
    "print(f\"y_test shape:\\t\\t{test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialise, train  and evaluate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 128, 300)          12000300  \n_________________________________________________________________\nbidirectional (Bidirectional (None, 128, 128)          186880    \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 128)               98816     \n_________________________________________________________________\ndense (Dense)                (None, 7)                 903       \n=================================================================\nTotal params: 12,286,899\nTrainable params: 286,599\nNon-trainable params: 12,000,300\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(40001, 300, weights=[w2v_emb_matrix], input_length=seq_length, trainable=False))\n",
    "model.add(Bidirectional(LSTM(64, dropout=0.5, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(64, dropout=0.5)))\n",
    "model.add(Dense(7, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "187/187 [==============================] - 15s 67ms/step - loss: 1.7236 - accuracy: 0.3248 - val_loss: 2.4869 - val_accuracy: 0.0971\n",
      "Epoch 2/5\n",
      "187/187 [==============================] - 12s 65ms/step - loss: 1.4053 - accuracy: 0.4803 - val_loss: 2.7979 - val_accuracy: 0.1263\n",
      "Epoch 3/5\n",
      "187/187 [==============================] - 13s 67ms/step - loss: 1.2378 - accuracy: 0.5592 - val_loss: 2.9963 - val_accuracy: 0.0944\n",
      "Epoch 4/5\n",
      "187/187 [==============================] - 12s 66ms/step - loss: 1.1490 - accuracy: 0.5852 - val_loss: 3.0972 - val_accuracy: 0.0851\n",
      "Epoch 5/5\n",
      "187/187 [==============================] - 12s 65ms/step - loss: 1.0776 - accuracy: 0.6166 - val_loss: 3.3174 - val_accuracy: 0.0878\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0fded7fa60>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "model.fit(train_X, train_y, validation_data=(val_X, val_y), batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23/23 [==============================] - 1s 18ms/step - loss: 4.2437 - accuracy: 0.0530\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[4.243688583374023, 0.05298912897706032]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. EWE embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ewe_emb_matrix:\t\t(40002, 300)\newe_word2idx shape:\t40001\nx_train shape:\t\t(5976, 128)\nx_validation shape:\t(752, 128)\nx_test shape:\t\t(736, 128)\ny_train shape:\t\t(5976, 7)\ny_validation shape:\t(752, 7)\ny_test shape:\t\t(736, 7)\n"
     ]
    }
   ],
   "source": [
    "ewe_emb_matrix, ewe_word2idx = read_embedding_matrix(ewe_embedding_file)\n",
    "print(f\"ewe_emb_matrix:\\t\\t{ewe_emb_matrix.shape}\")\n",
    "print(f\"ewe_word2idx shape:\\t{len(ewe_word2idx)}\")\n",
    "\n",
    "train_X, train_y = read_tsv(train_tsv, ewe_word2idx, oov_id=oov_id, pad_id=pad_id, seq_length=seq_length)\n",
    "val_X, val_y = read_tsv(val_tsv, ewe_word2idx, oov_id=oov_id, pad_id=pad_id, seq_length=seq_length)\n",
    "test_X, test_y = read_tsv(test_tsv, ewe_word2idx, oov_id=oov_id, pad_id=pad_id, seq_length=seq_length)\n",
    "\n",
    "print(f\"x_train shape:\\t\\t{train_X.shape}\")\n",
    "print(f\"x_validation shape:\\t{val_X.shape}\")\n",
    "print(f\"x_test shape:\\t\\t{test_X.shape}\")\n",
    "print(f\"y_train shape:\\t\\t{train_y.shape}\")\n",
    "print(f\"y_validation shape:\\t{val_y.shape}\")\n",
    "print(f\"y_test shape:\\t\\t{test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Custom word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 128, 300)          12000000  \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 128, 128)          186880    \n_________________________________________________________________\nbidirectional_3 (Bidirection (None, 128)               98816     \n_________________________________________________________________\ndense_1 (Dense)              (None, 7)                 903       \n=================================================================\nTotal params: 12,286,599\nTrainable params: 12,286,599\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(40001, 300, mask_zero=True, input_length=seq_length, embeddings_initializer=\"random_normal\"))\n",
    "model.add(Bidirectional(LSTM(64, dropout=0.5, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(64, dropout=0.5,)))\n",
    "model.add(Dense(7, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "187/187 [==============================] - 38s 176ms/step - loss: 1.5702 - accuracy: 0.4031 - val_loss: 2.8170 - val_accuracy: 0.0771\n",
      "Epoch 2/5\n",
      "187/187 [==============================] - 31s 163ms/step - loss: 0.9896 - accuracy: 0.6536 - val_loss: 3.6476 - val_accuracy: 0.0891\n",
      "Epoch 3/5\n",
      "187/187 [==============================] - 31s 168ms/step - loss: 0.6097 - accuracy: 0.7957 - val_loss: 4.4349 - val_accuracy: 0.0652\n",
      "Epoch 4/5\n",
      "187/187 [==============================] - 31s 165ms/step - loss: 0.3910 - accuracy: 0.8730 - val_loss: 5.1580 - val_accuracy: 0.0718\n",
      "Epoch 5/5\n",
      "187/187 [==============================] - 30s 163ms/step - loss: 0.2467 - accuracy: 0.9172 - val_loss: 6.1104 - val_accuracy: 0.0519\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0e9ef65be0>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.fit(train_X, train_y, validation_data=(val_X, val_y), batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23/23 [==============================] - 2s 23ms/step - loss: 6.5603 - accuracy: 0.0530\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[6.560274124145508, 0.05298912897706032]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model.evaluate(test_X, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}